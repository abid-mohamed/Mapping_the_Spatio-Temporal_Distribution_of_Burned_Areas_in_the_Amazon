---
title: "Stacked_Generaliser_2"
date: "`r Sys.Date()`"
output:
  html_document: 
    number_sections: yes
    fig_caption: yes
    toc: true
    toc_float: 
      collapsed: true
    theme: cerulean
    highlight: kate
    toc_depth: 5
    keep_md: yes
    df_print: paged
---

# Load libraries

```{r warning=FALSE, message=FALSE}
library(terra)
library(sf)
library(tidyverse)
library(data.table)
library(dplyr)
library(gdata)
# Parallel
library(foreach)
library(doSNOW)
library(parallel)
library(itertools)
# 
library(rsample)
library(recipes)
# Plot
library(RColorBrewer)
library(tidyterra)
library(scico)
library(wesanderson)
library(viridis)
library(scales)
library(latex2exp)
library(ggplot2)
# 
library(tictoc)
```

# Functions

```{r "Functions"}
random_dt <- function(DT) {
  DT.nrow <- nrow(DT)
  samp <- sample(1:DT.nrow, DT.nrow, replace=F)
  return(DT[samp,])
}
# Plot
myPlot <- function(rast, title=''){
  p <- ggplot()  +
    geom_spatraster(data = rast) +
    geom_spatvector(data = amaz.basin.shp$geometry, fill = NA, color = "gray40") +
    scale_x_continuous(labels = function(x) format(x, scientific = T)) +
    scale_y_continuous(labels = function(x) format(x, scientific = T)) +
    coord_sf(datum = pull_crs(rast)) +
    ggtitle(title)  +
    theme_bw()
  return(p)
}
```

# Initialization

```{r}
# Import shape file
amaz.basin.shp <- st_read("~/Documents/Amazon_new_data/0. Amazon_shapefile/projected/amazon_shp_projected.shp")

# path of variables
my.path <- "~/Documents"
path0 <- "/home/abidm/Documents"
burntArea.path <- "~/Documents/Amazon_new_data/1. Burnt Area/03. Working Data"
landCover.path <- "~/Documents/Amazon_new_data/2. Land Cover/03. Working Data"
precip.path <- "~/Documents/Amazon_new_data/3. Precipitation/03. Working Data"
soilMoisture.path <- "~/Documents/Amazon_new_data/4. Soil Moisture/03. Working Data"
elevation.path <- "~/Documents/Amazon_new_data/5. Elevation/03. Working Data"
LandSurfaceTemp.path <- "~/Documents/Amazon_new_data/6. LandSurfaceTemp/03. Working Data"
humidity.path <- "~/Documents/Amazon_new_data/7. Specific Humidity/03. Working Data"
evapotranspiration.path <- "~/Documents/Amazon_new_data/8. Evapotranspiration/03. Working Data"
wind.path <- "~/Documents/Amazon_new_data/9. Wind Speed/03. Working Data"
airtemp.path <- "~/Documents/Amazon_new_data/10. Air Temperature/03. Working Data"

x_min=-1.25e+06; x_max=0.05e+06; y_min=st_bbox(amaz.basin.shp)$ymin; y_max=2.4e+06    # South of Amazon            

# Number of years
nbrYears <- 20

# Number of cores to use
# nbrCores <- detectCores() - 1
nbrCores <- 45

# Color palette
my.colors <- c("mediumblue", "mediumseagreen", "firebrick")
pal <- colorRampPalette(c("mediumblue", "mediumseagreen", "firebrick"))

# Create a sequence of dates
sq.date <- seq(as.Date("2001-1-1"), as.Date("2020-12-1"), by = "month") %>% 
  format(., '%Y_%m') %>% 
  setdiff(., c("2012_07", "2012_09"))
```

# Load data ---- \\

```{r}
# tic() # 81.636 sec elapsed
# load(paste0(my.path,"/Amazon_selected_data/Amazon_zones_dt.Rdata"))
# toc()
# # Convert column `Zones` as factor
# Amazon.data.dt$Zones <- as.factor(Amazon.data.dt$Zones)

#--- Save data with zones
# save(Amazon.data.dt, file = paste0(my.path,"/Amazon_selected_data/Amazon_zonesFactor_dt.Rdata"))
tic() # 83.374 sec elapsed
load(paste0(my.path,"/Amazon_selected_data/Amazon_zonesFactor_dt.Rdata")) # Amazon.data.dt
toc()
Amazon.data.dt <- Amazon.data.dt[, c('cell'):=NULL]
```

# Normalize data \\

```{r}
# # recipe
# AZ_recipe <- recipe( BurntArea ~ ., data = Amazon.data.dt) %>% step_normalize(all_numeric(), -c(x, y))
#   # step_normalize(
#   #   Precipitation, SoilMoisture, Elevation, LandSurfaceTemp, Humidity, Evapotranspiration, Wind, AirTemp
#   # )
# # Normalize data
# tic() # 281.414 sec elapsed
# AZ.norm <- AZ_recipe %>% prep() %>% bake(new_data = NULL) %>% setcolorder(., c('Zones', 'x', 'y', 'Year', 'Month', 'BurntArea'))
# toc()
# rm(AZ_recipe)
# gc()

#--- Save data
# save(AZ.norm, file = paste0(my.path,"/Amazon_selected_data/AZ_norm.Rdata"))
tic() # 77.443 sec elapsed | 273.79
load(paste0(my.path,"/Amazon_selected_data/AZ_norm.Rdata"))
toc()
```

## Prepare data by zones \\

```{r}
tic()
for (zone in 2:10) {
  # ~ 2 min
  AZ.dt <- AZ.norm[AZ.norm$Zones == zone,]
  AZ.bar.dt <- AZ.norm[AZ.norm$Zones != zone,]
  
  #---- Randomise data ----
  cat("Randomize >")
  set.seed(11)
  tic() # 344.31 sec elapsed
  AZ.rnd <- random_dt(AZ.dt)
  AZ.bar <- random_dt(AZ.bar.dt)
  toc()
  
  #---- Create v-fold cross validation samples  ----
  cat("CV > \n")
  tic() # 56.3 sec elapsed 
  AZ.rnd.cv <- vfold_cv(AZ.rnd, v = 10,  strata = BurntArea)
  toc()
  #
  AZ.folds.lst <- list()
  for (i in 1:10){
    cat(" - Fold", i)
    AZ.folds.lst[[i]] <- AZ.rnd.cv$splits[[i]] %>% assessment() %>% add_column(Folds = i, .before = "x")
    AZ.folds.lst[[i]]$Folds <- as.factor(AZ.folds.lst[[i]]$Folds)
  }
  #---- Add column `Folds` to the data ----
  AZ <- rbindlist(AZ.folds.lst, use.names = T, fill = T)
  
  #--- Save data ----
  cat("\n Save >")
  save(AZ, file = paste0(my.path,"/Amazon_selected_data/data_by_zones_sg/AZ", zone, ".Rdata"))
  save(AZ.bar, file = paste0(my.path,"/Amazon_selected_data/data_by_zones_sg/AZ", zone, "bar.Rdata"))
  toc()
  rm(AZ.dt, AZ.bar.dt, AZ.rnd, AZ.bar, AZ.rnd.cv, AZ)
}
toc()
```

# Initialize and Connect to H2O 

```{r}
options(java.parameters = "-Xmx700g")
Sys.setenv("OPENBLAS_MAIN_FREE"=1)

library(h2o)
localH2O <- h2o.init(ip = 'localhost', port = 50001, nthreads = 45, max_mem_size = '700g')
```


```{r}
# tic() # __ sec elapsed
# AZ.cv <- nested_cv(AZ.norm,
#                    group_vfold_cv(group = Zones),
#                    vfold_cv(v = 10,  strata = BurntArea))
# toc()
# 
# #--- Save data
# save(AZ.cv, file = paste0(my.path,"/Amazon_selected_data/AZ_cv.Rdata"))
# # tic() # __ sec elapsed
# # load(paste0(my.path,"/Amazon_selected_data/AZ_cv.Rdata"))
# # toc()
```

#=======================

# ---> Select a zone

```{r}
zone <- 1
```

# Load data

```{r}
zone <- 1
#---- Load data ----
tic() # 260.874 sec elapsed
load(paste0(my.path,"/Amazon_selected_data/data_by_zones_sg/AZ", zone, ".Rdata"))
load(paste0(my.path,"/Amazon_selected_data/data_by_zones_sg/AZ", zone, "bar.Rdata"))
toc()
#---- Rename ----
mv(from = paste0("AZ", zone), to = "AZ")
mv(from = paste0("AZ", zone, "bar"), to = "AZ.bar")
```

```{r}
#---- Convert data to H2O objects ----
var.names <- colnames(AZ)
Y <- "BurntArea"
covt.names <- setdiff(var.names, c("BurntArea", "Folds"))
tic() # 34.446 sec elapsed
AZ.h2o <- as.h2o(AZ)
toc()
```

## Gradient Boosting Machine (GBM)

```{r}
# 50 M observations | 27783.421 sec ~ 7.7 h | Memory: __ Gb
 n.trees = 1000; m.tries = 0.6
tic()
gbm.az1 <- h2o.gbm(
  model_id = paste0("GBM_AZ", zone),
  x = covt.names, 
  y = Y, 
  training_frame = AZ.h2o,
  fold_column = "Folds",
  keep_cross_validation_predictions = TRUE,
  ntrees = n.trees, 
  col_sample_rate = m.tries,
  score_each_iteration = TRUE
)
toc()

#---- Save the model
# gbm.az1.path <- h2o.saveModel(
#   object = gbm.az1,
#   path = paste0(path0, "/SG_models"),
#   force = FALSE,
#   export_cross_validation_predictions = TRUE,
#   filename = "GBM_AZ1_model"
# )
#---- Load model
h2o.upload_model(paste0(path0, "/SG_models/GBM_AZ1_model"))

h2o.predict(gbm, newdata=h2odat)



ntrees<-gbm@parameters$ntrees 
	 tmp = h2o.predict(gbm, newdata=h2odat)
	 fit.gbm=as.vector(tmp$predict) 
#	   sh <- lapply(m@model$cross_validation_models, function(r) { h2o.getModel(r$name)@model$scoring_history })
	 h2o.saveModel(gbm, path=paste0('/home/backup/StackedGeneraliser/models/',zone,'/'), force = TRUE)
 	gbm.extrap<-h2o.predict(gbm,newdata=extrap)
 	gbm.extrap<-drop(as.vector(gbm.extrap$predict))
 
	cv.gbm<-rep(NA,nrow(data))
  for(i in 1:nfolds){
    train <- h2odat[h2odat$folds!=i,]
    gbm <- h2o.gbm(
      y = "Y", x = covariate.names,
      distribution="gaussian",
      training_frame = train,
      ntrees=ntrees, max_depth=max_depth, learn_rate=learn_rate,
      sample_rate=sample_rate,col_sample_rate=col_sample_rate,min_rows=min_rows
    )
    valid <- h2odat[h2odat$folds==i,]
    tmp <- h2o.predict(gbm, newdata=valid)
    cv.gbm[as.logical(as.vector((h2odat$folds==i)))]=as.vector(tmp$predict)
    tmp<-c()
	}	
```


```{r}
gbm.az1@parameters$ntrees
   sh <- lapply(gbm.az1@model$cross_validation_models, function(r) { h2o.getModel(r$name)@model$scoring_history })

```





# Clear and Shutdown H2O

```{r}
h2o.removeAll()
h2o:::.h2o.garbageCollect()
h2o:::.h2o.garbageCollect()
h2o:::.h2o.garbageCollect()
h2o.ls()
# h2o.shutdown(prompt = FALSE)
```

















































































































