---
title: "Preparation_Amazon_data"
date: "2022-12-28"
output:
  html_document: 
    number_sections: yes
    fig_caption: yes
    toc: true
    toc_float: 
      collapsed: false
    theme: cerulean
    highlight: kate
    toc_depth: 5
    keep_md: yes
    df_print: paged
---

# Load libraries

```{r, load libraries, warning=FALSE, message=FALSE}
# load libraries
library(tictoc)
library(tidyverse)
# library(raster)
library(terra)
library(sf)
# library(rgdal)
# library(ggplot2)
library(RColorBrewer)
# library(rts)
library(doParallel)
library(parallel)
library(foreach)
library(data.table)
library(dplyr)
library(fastDummies)
library(randomForest)
library(caTools)
library(rpart)
library(VSURF)
my.path <- "~/Documents/"
```

# Functions

```{r "Functions"}
# # Function to save layers
# saveLayers = function(dataRast, shapeFile, pathFile, strRemove,
#                       x_min=xmin(dataRast), x_max=xmax(dataRast), 
#                       y_min=ymin(dataRast), y_max=ymax(dataRast)){
#   
#   # Iterate all the layers
#   for (i in 1:nlyr(dataRast)){
#     print(i)
#     dataRast.i <- dataRast[[i]]
#     # Crop data
#     dataRast.basin.i <- mask(dataRast.i, mask = shapeFile) %>%
#       crop(ext(x_min, x_max, y_min, y_max))
#     # Path of the file
#     path <- gsub(strRemove, "", names(dataRast.basin.i)) %>%
#       paste0(pathFile, ., ".tif")
#     # Save file
#     writeRaster(dataRast.basin.i, path, overwrite=TRUE)
#     # Clear memory
#     gc()
#   }
# }

# # Function to rename layers
# renameLayers <- function(dataRast, fileStart, prefix){
#   # index of file name in the path
#   id.date <- unlist(gregexpr(fileStart, sources(dataRast)[[1]])) + nchar(fileStart)
#   # rename layers
#   names(dataRast) <-
#     substr(sources(dataRast), id.date, (id.date+50)) %>%
#     gsub(".tif", "_1", .) %>%
#     as.Date("%Y_%m_%d") %>%
#     format(., '%Y_%m') %>%
#     paste0(prefix, .)
# 
#   return(dataRast)
# }

# Function to rename layers
renameRast <- function(dataRast, fileStart, prefix){
  library(data.table)
  # index of file name in the path
  id.date <- unlist(gregexpr(fileStart, sources(dataRast)[[1]])) + nchar(fileStart)
  # rename layers
  dateRast <- 
    substr(sources(dataRast), id.date, (id.date+50)) %>%
    gsub(".tif", "_1", .) %>%
    as.Date("%Y_%m_%d")
  # Rename layers
  names(dataRast) <- 
    dateRast %>%
    format(., '%Y_%m') %>%
    paste0(prefix, .)
  yearRast <- data.table::year(dateRast)
  monthRast <- data.table::month(dateRast)
  # return
  return(list(dataRast, yearRast, monthRast))
}
```

#=====================

# Import shape file

```{r}
# Import shape file
amaz.basin.shp <- st_read("~/Documents/Amazon_new_data/0. Amazon_shapefile/projected/amazon_shp_projected.shp")
```

# Initialization

```{r}
# path of variables
burntArea.path <- "~/Documents/Amazon_new_data/1. Burnt Area/03. Working Data"
landCover.path <- "~/Documents/Amazon_new_data/2. Land Cover/03. Working Data"
precip.path <- "~/Documents/Amazon_new_data/3. Precipitation/03. Working Data"
soilMoisture.path <- "~/Documents/Amazon_new_data/4. Soil Moisture/03. Working Data"
elevation.path <- "~/Documents/Amazon_new_data/5. Elevation/03. Working Data"
LandSurfaceTemp.path <- "~/Documents/Amazon_new_data/6. LandSurfaceTemp/03. Working Data"
humidity.path <- "~/Documents/Amazon_new_data/7. Specific Humidity/03. Working Data"
evapotranspiration.path <- "~/Documents/Amazon_new_data/8. Evapotranspiration/03. Working Data"
wind.path <- "~/Documents/Amazon_new_data/9. Wind Speed/03. Working Data"
airtemp.path <- "~/Documents/Amazon_new_data/10. Air Temperature/03. Working Data"

path.list <- c(
  burntArea.path, 
  landCover.path, 
  precip.path, 
  soilMoisture.path, 
  elevation.path, 
  LandSurfaceTemp.path, 
  humidity.path, 
  evapotranspiration.path, 
  wind.path,
  airtemp.path
)

x_min=-1.25e+06; x_max=0.05e+06; y_min=st_bbox(amaz.basin.shp)$ymin; y_max=2.4e+06    # South of Amazon
# x_min=-0.8e+06; x_max=-0.4e+06; y_min=1.8e+06; y_max=2.2e+06
# x_min=-0.6e+06; x_max=-0.4e+06; y_min=2.0e+06; y_max=2.2e+06                          
# x_min=-0.5e+06; x_max=-0.4e+06; y_min=2.0e+06; y_max=2.1e+06                          # 200 x 200 | 10 Y DF 20 M -> 70 Gb | 5 Y DF 10 M -> 17.5 Gb | 3Y DF 1.4 M -> 10.5 Gb | 2Y DF 0.96 M -> 3.5 Gb

# Number of years
nbrYears <- 20

# Number of cores to use
# nbrCores <- detectCores() - 1
nbrCores <- 30
```

# * =====================

# Create dataframe

```{r}
# #Register cluster for parallel processing: Cores to use: all except 1
# cl <- parallel::makeCluster(nbrCores)
# doParallel::registerDoParallel(cl)
# tic()
# dtlist2 <- 
#   foreach (var.path=path.list[1:2], .combine='rbind') %do% {
#     cat("\n>> ", var.path, " #\n")
#     # list of files
#     amaz.var.list <- list.files(var.path, full.names=TRUE, pattern = ".tif$")
#     amaz.var.list <- amaz.var.list[1 : (12*nbrYears)]
#     
#     foreach(ras_id=amaz.var.list, .packages=c('terra', 'sf', 'data.table'), .combine='c') %dopar% {
#       #Read all rasters into one big stack
#       ras <- rast(ras_id)
#       
#       # Rename layers
#       ras.Y.M <- renameRast(ras, 'burntarea_working_', '')
#       ras <- ras.Y.M[[1]]
#       
#       # Replace negative value by `NA`
#       ras[ras %in% c(-2, -1)] <- NA
#       
#       # Crop data
#       ras <- ras %>% crop(ext(x_min, x_max, y_min, y_max)) # %>% mask(mask = amaz.basin.shp)
#       
#       #Convert to data.frame then to data.table
#       DT <- terra::as.data.frame(ras, xy=T)
#       
#       Year <- rep(ras.Y.M[[2]], dim(DT)[1])
#       Month <- rep(ras.Y.M[[3]], dim(DT)[1])
#       #
#       DT <- cbind(DT, Year, Month)
#   
#       colnames(DT)[3:5] <- c("burntArea", "Year", "Month")
#       setcolorder(DT, c('x', 'y', 'Year', 'Month'))
#       
#       DT <- na.omit(DT)
#       
#       dtlist <- list(DT)
#     }
#     var.dt <- rbindlist(dtlist, fill=T, use.names=T)
#   }
# stopCluster(cl)
# toc()
```

## Burnt Area

```{r}
#Register cluster for parallel processing: Cores to use: all except 1
# cl <- parallel::makeCluster(nbrCores)
# cl <- parallel::makeCluster(nbrCores)
doParallel::registerDoParallel(cores=nbrCores)

# list of files

amaz.var.list <- list.files(burntArea.path, full.names=TRUE, pattern = ".tif$")
amaz.var.list <- amaz.var.list[1 : (12*nbrYears)]

tic("burntArea")
#Raster to datatable in parallel: one raster per thread
dtlist <- 
  foreach (ras_id=amaz.var.list, 
           .packages=c('terra', 'sf', 'data.table'), 
           .combine='c') %dopar% 
  {
    # Read all rasters
    ras <- rast(ras_id)
    
    # Rename layers
    ras.Y.M <- renameRast(ras, 'burntarea_working_', '')
    ras <- ras.Y.M[[1]]
    
    # Crop data 
    ras <- ras %>% crop(ext(x_min, x_max, y_min, y_max)) %>% mask(mask = amaz.basin.shp)
    
    # Replace -2 and -1 value by `NA`
    ras[ras %in% c(-2, -1)] <- NA
    
    # Convert to data.frame
    DT <- terra::as.data.frame(ras, xy=T)
    
    # Add Year and Month as factors
    Year <- rep(ras.Y.M[[2]], dim(DT)[1]) %>% as.factor()
    Month <- rep(ras.Y.M[[3]], dim(DT)[1]) %>% as.factor()
    DT <- cbind(DT, Year, Month)

    # Modification of the data
    colnames(DT)[3:5] <- c("burntArea", "Year", "Month")
    setcolorder(DT, c('x', 'y', 'Year', 'Month'))
    DT$burntArea <- as.factor(DT$burntArea)
    DT <- na.omit(DT)
    
    # Return df in a list
    list(DT)
  }
# stopCluster(cl)

#Bind all per-raster datatables into one big table
burntArea.dt <- rbindlist(dtlist, fill=T, use.names=T)

# Remove column "Year" if we have only one year.
# if(nbrYears==1){burntArea.dt[,Year:=NULL]}

toc()
burntArea.dt
rm(dtlist)
gc()
```

burntArea: 100.663 sec elapsed

```{r}
# tic()
# saveRDS(burntArea.dt, file = "~/Documents/Rds/burntArea_20Y_south.Rds")
# toc()
```

## Land Cover data

```{r}
#Register cluster for parallel processing: Cores to use: all except 1
cl <- parallel::makeCluster(nbrCores)
doParallel::registerDoParallel(cl)

# list of files

amaz.var.list <- list.files(landCover.path, full.names=TRUE, pattern = ".tif$")
amaz.var.list <- amaz.var.list[1:(12*nbrYears)]

tic("landCover")
#Raster to datatable in parallel: one raster per thread
dtlist <- 
  foreach (ras_id=amaz.var.list, 
           .packages=c('terra', 'sf', 'data.table'), 
           .combine='c') %dopar% 
  {
    # Read all rasters
    ras <- rast(ras_id)
    
    # Rename layers
    ras.Y.M <- renameRast(ras, 'landcover_working_', '')
    ras <- ras.Y.M[[1]]
    
    # Crop data and convert to data.frame 
    ras <- ras %>% crop(ext(x_min, x_max, y_min, y_max)) %>% mask(mask = amaz.basin.shp)
    DT <- terra::as.data.frame(ras, xy=T)
    
    # Add Year and Month as factors
    Year <- rep(ras.Y.M[[2]], dim(DT)[1]) %>% as.factor()
    Month <- rep(ras.Y.M[[3]], dim(DT)[1]) %>% as.factor()
    DT <- cbind(DT, Year, Month)
    
    # Modification of the data
    colnames(DT)[3:5] <- c("landCover", "Year", "Month")
    setcolorder(DT, c('x', 'y', 'Year', 'Month'))
    # Convert data as factor ------<<<
    DT$landCover <- as.factor(DT$landCover)
    DT <- na.omit(DT)
    
    # Return df in a list
    list(DT)
  }
stopCluster(cl)

#Bind all per-raster datatables into one big table
landCover.dt <- rbindlist(dtlist, fill=T, use.names=T)
toc()

landCover.dt
rm(dtlist)
gc()
```

```{r}
# tic()
# saveRDS(landCover.dt, file = "~/Documents/Rds/landCover_20Y_south.Rds")
# toc()
```

## Precipitation data

```{r}
#Register cluster for parallel processing: Cores to use: all except 1
cl <- parallel::makeCluster(nbrCores)
doParallel::registerDoParallel(cl)

# list of files

amaz.var.list <- list.files(precip.path, full.names=TRUE, pattern = ".tif$")
amaz.var.list <- amaz.var.list[1:(12*nbrYears)]

tic("precipitation")
#Raster to datatable in parallel: one raster per thread
dtlist <- 
  foreach (ras_id=amaz.var.list, 
           .packages=c('terra', 'sf', 'data.table'), 
           .combine='c') %dopar% 
  {
    # Read raster
    ras <- rast(ras_id)
    
    # Rename layers
    ras.Y.M <- renameRast(ras, 'precipitation_working_', '')
    ras <- ras.Y.M[[1]]
    
    # Crop data and convert to data.frame 
    ras <- ras %>% crop(ext(x_min, x_max, y_min, y_max)) %>% mask(mask = amaz.basin.shp)
    DT <- terra::as.data.frame(ras, xy=T)
    
    # Add Year and Month as factors
    Year <- rep(ras.Y.M[[2]], dim(DT)[1]) %>% as.factor()
    Month <- rep(ras.Y.M[[3]], dim(DT)[1]) %>% as.factor()
    DT <- cbind(DT, Year, Month)

    # Modification of the data
    colnames(DT)[3:5] <- c("precipitation", "Year", "Month")
    setcolorder(DT, c('x', 'y', 'Year', 'Month'))
    DT <- na.omit(DT)
    
    # Return df in a list
    list(DT)
  }
stopCluster(cl)

#Bind all per-raster datatables into one big table
precipitation.dt <- rbindlist(dtlist, fill=T, use.names=T)
toc()

precipitation.dt
rm(dtlist)
gc()
```

```{r}
# tic()
# saveRDS(precipitation.dt, file = "~/Documents/Rds/precipitation_20Y_south.Rds")
# toc()
```

## Soil Moisture data

```{r}
#Register cluster for parallel processing: Cores to use: all except 1
cl <- parallel::makeCluster(nbrCores)
doParallel::registerDoParallel(cl)

# list of files
 
amaz.var.list <- list.files(soilMoisture.path, full.names=TRUE, pattern = ".tif$")
amaz.var.list <- amaz.var.list[1:(12*nbrYears)]

tic("soilMoisture")
#Raster to datatable in parallel: one raster per thread
dtlist <- 
  foreach (ras_id=amaz.var.list, 
           .packages=c('terra', 'sf', 'data.table'), 
           .combine='c') %dopar% 
  {
    # Read all rasters
    ras <- rast(ras_id)
    
    # Rename layers
    ras.Y.M <- renameRast(ras, 'soilmoisture_working_', '')
    ras <- ras.Y.M[[1]]
    
    # Crop data 
    ras <- ras %>% crop(ext(x_min, x_max, y_min, y_max)) %>% mask(mask = amaz.basin.shp)
    
    # Remove negative values.------<<<
    ras[ras < 0] <- NA
    
    # Convert to data.frame
    DT <- terra::as.data.frame(ras, xy=T)
    
    # Add Year and Month as factors
    Year <- rep(ras.Y.M[[2]], dim(DT)[1]) %>% as.factor()
    Month <- rep(ras.Y.M[[3]], dim(DT)[1]) %>% as.factor()
    DT <- cbind(DT, Year, Month)

    # Modification of the data
    colnames(DT)[3:5] <- c("soilMoisture", "Year", "Month")
    setcolorder(DT, c('x', 'y', 'Year', 'Month'))
    DT <- na.omit(DT)
    
    list(DT)
  }
stopCluster(cl)

#Bind all per-raster datatables into one big table
soilMoisture.dt <- rbindlist(dtlist, fill=T, use.names=T)
toc()

soilMoisture.dt
rm(dtlist)
gc()
```

```{r}
# tic()
# saveRDS(soilMoisture.dt, file = "~/Documents/Rds/soilMoisture_20Y_south.Rds")
# toc()
```

## Elevation data

### Create files

```{r}
# prefix <- paste0(elevation.path, "/elevation_working_")
# new.files <- seq(as.Date("2001-1-1"), as.Date("2020-12-1"), by = "month") %>%
#     format(., '%Y_%m') %>%
#     paste0(prefix, ., ".tif")
#     
# file.copy(paste0(elevation.path,"/elevation_working.tif"), new.files)
```


```{r}
#Register cluster for parallel processing: Cores to use: all except 1
cl <- parallel::makeCluster(nbrCores)
doParallel::registerDoParallel(cl)

# list of files

amaz.var.list <- list.files(elevation.path, full.names=TRUE, pattern = ".tif$")
amaz.var.list <- amaz.var.list[1:(12*nbrYears)]

tic("elevation")
#Raster to datatable in parallel: one raster per thread
dtlist <- 
  foreach (ras_id=amaz.var.list, 
           .packages=c('terra', 'sf', 'data.table'),
           .combine='c') %dopar% 
  {
    # Read all rasters
    ras <- rast(ras_id)
    
    # Rename layers
    ras.Y.M <- renameRast(ras, 'elevation_working_', '')
    ras <- ras.Y.M[[1]]
    
    # Crop data and convert to data.frame 
    ras <- ras %>% crop(ext(x_min, x_max, y_min, y_max)) %>% mask(mask = amaz.basin.shp)
    DT <- terra::as.data.frame(ras, xy=T)
    
    # Add Year and Month as factors
    Year <- rep(ras.Y.M[[2]], dim(DT)[1]) %>% as.factor()
    Month <- rep(ras.Y.M[[3]], dim(DT)[1]) %>% as.factor()
    DT <- cbind(DT, Year, Month)

    # Modification of the data
    colnames(DT)[3:5] <- c("elevation", "Year", "Month")
    setcolorder(DT, c('x', 'y', 'Year', 'Month'))
    DT <- na.omit(DT)
    
    # Return df in a list
    list(DT)
  }
stopCluster(cl)

#Bind all per-raster datatables into one big table
elevation.dt <- rbindlist(dtlist, fill=T, use.names=T)
toc()

elevation.dt
rm(dtlist)
gc()
```

```{r}
# tic()
# saveRDS(elevation.dt, file = "~/Documents/Rds/elevation_20Y_south.Rds")
# toc()
```

## LandSurfaceTemp data

```{r}
#Register cluster for parallel processing: Cores to use: all except 1
cl <- parallel::makeCluster(nbrCores)
doParallel::registerDoParallel(cl)

# list of files

amaz.var.list <- list.files(LandSurfaceTemp.path, full.names=TRUE, pattern = ".tif$")
amaz.var.list <- amaz.var.list[1:(12*nbrYears)]

tic("LandSurfaceTemp")
#Raster to datatable in parallel: one raster per thread
dtlist <- 
  foreach (ras_id=amaz.var.list, 
           .packages=c('terra', 'sf', 'data.table'), 
           .combine='c') %dopar% 
  {
    # Read all rasters
    ras <- rast(ras_id)
    
    # Rename layers
    ras.Y.M <- renameRast(ras, 'landsurftemp_working_', '')
    ras <- ras.Y.M[[1]]
    
    # Crop data and convert to data.frame 
    ras <- ras %>% crop(ext(x_min, x_max, y_min, y_max)) %>% mask(mask = amaz.basin.shp)
    DT <- terra::as.data.frame(ras, xy=T)
    
    # Add Year and Month as factors
    Year <- rep(ras.Y.M[[2]], dim(DT)[1]) %>% as.factor()
    Month <- rep(ras.Y.M[[3]], dim(DT)[1]) %>% as.factor()
    DT <- cbind(DT, Year, Month)

    # Modification of the data
    colnames(DT)[3:5] <- c("landsurftemp", "Year", "Month")
    setcolorder(DT, c('x', 'y', 'Year', 'Month'))
    DT <- na.omit(DT)
    
    # Return df in a list
    list(DT)
  }
stopCluster(cl)

#Bind all per-raster datatables into one big table
landsurftemp.dt <- rbindlist(dtlist, fill=T, use.names=T)
toc()

landsurftemp.dt
rm(dtlist)
gc()
```

```{r}
# tic()
# saveRDS(landsurftemp.dt, file = "~/Documents/Rds/landsurftemp_20Y_south.Rds")
# toc()
```

## Specific Humidity data

```{r}
#Register cluster for parallel processing: Cores to use: all except 1
cl <- parallel::makeCluster(nbrCores)
doParallel::registerDoParallel(cl)

# list of files

amaz.var.list <- list.files(humidity.path, full.names=TRUE, pattern = ".tif$")
amaz.var.list <- amaz.var.list[1:(12*nbrYears)]

tic("humidity")
#Raster to datatable in parallel: one raster per thread
dtlist <- 
  foreach (ras_id=amaz.var.list, 
           .packages=c('terra', 'sf', 'data.table'), 
           .combine='c') %dopar% 
  {
    # Read all rasters
    ras <- rast(ras_id)
    
    # Rename layers
    ras.Y.M <- renameRast(ras, 'humidity_working_', '')
    ras <- ras.Y.M[[1]]
    
    # Crop data and convert to data.frame 
    ras <- ras %>% crop(ext(x_min, x_max, y_min, y_max)) %>% mask(mask = amaz.basin.shp)
    DT <- terra::as.data.frame(ras, xy=T)
    
    # Add Year and Month as factors
    Year <- rep(ras.Y.M[[2]], dim(DT)[1]) %>% as.factor()
    Month <- rep(ras.Y.M[[3]], dim(DT)[1]) %>% as.factor()
    DT <- cbind(DT, Year, Month)

    # Modification of the data
    colnames(DT)[3:5] <- c("humidity", "Year", "Month")
    setcolorder(DT, c('x', 'y', 'Year', 'Month'))
    DT <- na.omit(DT)
    
    # Return df in a list
    list(DT)
  }
stopCluster(cl)

#Bind all per-raster datatables into one big table
humidity.dt <- rbindlist(dtlist, fill=T, use.names=T)
toc()

humidity.dt
rm(dtlist)
gc()
```

```{r}
# tic()
# saveRDS(humidity.dt, file = "~/Documents/Rds/humidity_20Y_south.Rds")
# toc()
```

## Evapotranspiration data

```{r}
#Register cluster for parallel processing: Cores to use: all except 1
cl <- parallel::makeCluster(nbrCores)
doParallel::registerDoParallel(cl)

# list of files

amaz.var.list <- list.files(evapotranspiration.path, full.names=TRUE, pattern = ".tif$")
amaz.var.list <- amaz.var.list[1:(12*nbrYears)]

tic("evapotranspiration")
#Raster to datatable in parallel: one raster per thread
dtlist <- 
  foreach (ras_id=amaz.var.list, 
           .packages=c('terra', 'sf', 'data.table'), 
           .combine='c') %dopar% 
  {
    # Read all rasters
    ras <- rast(ras_id)
    
    # Rename layers
    ras.Y.M <- renameRast(ras, 'evapotranspiration_working_', '')
    ras <- ras.Y.M[[1]]
    
    # Crop data and convert to data.frame 
    ras <- ras %>% crop(ext(x_min, x_max, y_min, y_max)) %>% mask(mask = amaz.basin.shp)
    DT <- terra::as.data.frame(ras, xy=T)
    
    # Add Year and Month as factors
    Year <- rep(ras.Y.M[[2]], dim(DT)[1]) %>% as.factor()
    Month <- rep(ras.Y.M[[3]], dim(DT)[1]) %>% as.factor()
    DT <- cbind(DT, Year, Month)

    # Modification of the data
    colnames(DT)[3:5] <- c("evapotranspiration", "Year", "Month")
    setcolorder(DT, c('x', 'y', 'Year', 'Month'))
    DT <- na.omit(DT)
    
    # Return df in a list
    list(DT)
  }
stopCluster(cl)

#Bind all per-raster datatables into one big table
evapotranspiration.dt <- rbindlist(dtlist, fill=T, use.names=T)
toc()

evapotranspiration.dt
rm(dtlist)
gc()
```

```{r}
# tic()
# saveRDS(evapotranspiration.dt, file = "~/Documents/Rds/evapotranspiration_20Y_south.Rds")
# toc()
```

## Wind Speed data

```{r}
#Register cluster for parallel processing: Cores to use: all except 1
cl <- parallel::makeCluster(nbrCores)
doParallel::registerDoParallel(cl)

# list of files

amaz.var.list <- list.files(wind.path, full.names=TRUE, pattern = ".tif$")
amaz.var.list <- amaz.var.list[1:(12*nbrYears)]

tic("wind")
#Raster to datatable in parallel: one raster per thread
dtlist <- 
  foreach (ras_id=amaz.var.list, 
           .packages=c('terra', 'sf', 'data.table'), 
           .combine='c') %dopar% 
  {
    # Read all rasters
    ras <- rast(ras_id)
    
    # Rename layers
    ras.Y.M <- renameRast(ras, 'wind_working_', '')
    ras <- ras.Y.M[[1]]
    
    # Crop data and convert to data.frame 
    ras <- ras %>% crop(ext(x_min, x_max, y_min, y_max)) %>% mask(mask = amaz.basin.shp)
    DT <- terra::as.data.frame(ras, xy=T)
    
    # Add Year and Month as factors
    Year <- rep(ras.Y.M[[2]], dim(DT)[1]) %>% as.factor()
    Month <- rep(ras.Y.M[[3]], dim(DT)[1]) %>% as.factor()
    DT <- cbind(DT, Year, Month)

    # Modification of the data
    colnames(DT)[3:5] <- c("wind", "Year", "Month")
    setcolorder(DT, c('x', 'y', 'Year', 'Month'))
    DT <- na.omit(DT)
    
    # Return df in a list
    list(DT)
  }
stopCluster(cl)

#Bind all per-raster datatables into one big table
wind.dt <- rbindlist(dtlist, fill=T, use.names=T)
toc()

wind.dt
rm(dtlist)
gc()
```

```{r}
# tic()
# saveRDS(wind.dt, file = "~/Documents/Rds/wind_20Y_south.Rds")
# toc()
```

## Air Temperature data

```{r}
#Register cluster for parallel processing: Cores to use: all except 1
cl <- parallel::makeCluster(nbrCores)
doParallel::registerDoParallel(cl)

# list of files

amaz.var.list <- list.files(airtemp.path, full.names=TRUE, pattern = ".tif$")
amaz.var.list <- amaz.var.list[1:(12*nbrYears)]

tic("airtemp")
#Raster to datatable in parallel: one raster per thread
dtlist <- 
  foreach (ras_id=amaz.var.list, 
           .packages=c('terra', 'sf', 'data.table'), 
           .combine='c') %dopar% 
  {
    # Read all rasters
    ras <- rast(ras_id)
    
    # Rename layers
    ras.Y.M <- renameRast(ras, 'airtemp_working_', '')
    ras <- ras.Y.M[[1]]
    
    # Crop data and convert to data.frame 
    ras <- ras %>% crop(ext(x_min, x_max, y_min, y_max)) %>% mask(mask = amaz.basin.shp)
    DT <- terra::as.data.frame(ras, xy=T)
    
    # Add Year and Month as factors
    Year <- rep(ras.Y.M[[2]], dim(DT)[1]) %>% as.factor()
    Month <- rep(ras.Y.M[[3]], dim(DT)[1]) %>% as.factor()
    DT <- cbind(DT, Year, Month)

    # Modification of the data
    colnames(DT)[3:5] <- c("airtemp", "Year", "Month")
    setcolorder(DT, c('x', 'y', 'Year', 'Month'))
    DT <- na.omit(DT)
    
    # Return df in a list
    list(DT)
  }
stopCluster(cl)

#Bind all per-raster datatables into one big table
airtemp.dt <- rbindlist(dtlist, fill=T, use.names=T)
toc()

airtemp.dt
rm(dtlist)
gc()
```

```{r}
# tic()
# saveRDS(airtemp.dt, file = "~/Documents/Rds/airtemp_20Y_south.Rds")
# toc()
```

#---------------------

# Load variables

```{r}
# tic()
# burntArea.dt <- readRDS("~/Documents/Rds/burntArea_20Y_south.Rds")
# landCover.dt <- readRDS("~/Documents/Rds/landCover_20Y_south.Rds")
# precipitation.dt <- readRDS("~/Documents/Rds/precipitation_20Y_south.Rds")
# soilMoisture.dt <- readRDS("~/Documents/Rds/soilMoisture_20Y_south.Rds")
# elevation.dt <- readRDS("~/Documents/Rds/elevation_20Y_south.Rds")
# landsurftemp.dt <- readRDS("~/Documents/Rds/landsurftemp_20Y_south.Rds")
# humidity.dt <- readRDS("~/Documents/Rds/humidity_20Y_south.Rds")
# evapotranspiration.dt <- readRDS("~/Documents/Rds/evapotranspiration_20Y_south.Rds")
# wind.dt <- readRDS("~/Documents/Rds/wind_20Y_south.Rds")
# airtemp.dt <- readRDS("~/Documents/Rds/airtemp_20Y_south.Rds")
# toc()
```

398.818 sec elapsed

# Merge all datatables.

```{r "11.1.merge"}
tic()
amazon.south.dt <- list(burntArea.dt,
                  landCover.dt,
                  precipitation.dt,
                  soilMoisture.dt,
                  elevation.dt,
                  landsurftemp.dt,
                  humidity.dt,
                  evapotranspiration.dt,
                  wind.dt,
                  airtemp.dt) %>%
  reduce(inner_join, by=c("x", "y", "Year", "Month"))
toc()
```

4002.134 sec elapsed

```{r}
amazon.south.dt
```

# Save data

```{r}
# tic()
# data.table::fwrite(amazon.south.dt, "~/Documents/csv/amazon_south.csv", sep=";")
# toc()
```

100.231 sec elapsed  -> 84.7 Gb

```{r}
# tic()
# saveRDS(amazon.south.dt, file = "~/Documents/Rds/amazon_south.Rds")
# toc()
```

762.359 sec elapsed -> 2.2 Gb

# Remove variables

```{r}
rm(
  burntArea.dt,
  landCover.dt,
  precipitation.dt,
  soilMoisture.dt,
  elevation.dt,
  landsurftemp.dt,
  humidity.dt,
  evapotranspiration.dt,
  wind.dt,
  airtemp.dt
)
gc()
```

#=====================

# Prepare data

## Load raster data

```{r}
library(rts)
# Load data
amaz.burntArea.list <- list.files(burntArea.path, full.names=TRUE, pattern = ".tif$")
burntArea.rast <- rast(amaz.burntArea.list)
# Rename layers
burntArea.rast <- renameRast(burntArea.rast, 'burntarea_working_', 'fire_')[[1]]
# Order layers
ordered.names.1 <- seq(as.Date("2001-1-1"), as.Date("2020-12-1"), by = "month") %>% 
  format(., '%Y_%m') %>%
  paste0("fire_", .)
burntArea.rast <- burntArea.rast[[ordered.names.1]]
# Create a sequence date for 'rts' object
seq.dates <- seq(as.Date("2001-1-1"), as.Date("2020-12-1"), by = "month")
# create rts object
burntArea.rts <- rts(burntArea.rast, seq.dates)
```

## Plot the region

```{r}
# Select a region
x2_min=-0.88e+06; x2_max=-0.38e+06; y2_min=1.9e+06; y2_max=2.4e+06
e <- ext(x2_min, x2_max, y2_min, y2_max)
# Plot all amazon region
pal <- colorRampPalette(c("lightblue", "forestgreen", "firebrick"))
burntArea.rts[['2020-10-01']] %>% 
  mask(mask = amaz.basin.shp) %>% 
  plot(col=pal(3), main="Burnt area in October 2020")
plot(amaz.basin.shp$geometry, add=T)
plot(e, add=T)
# Plot with zoom
pal <- colorRampPalette(c("lightblue", "forestgreen", "firebrick"))
burntArea.rts[['2020-10-01']] %>% 
  crop(ext(x_min, x_max, y_min, y_max)) %>% 
  mask(mask = amaz.basin.shp) %>% 
  plot(col=pal(3), main="Burnt area in October 2020")
plot(amaz.basin.shp$geometry, add=T)
plot(e, add=T)
```
#-------------------

# Load the datatable

```{r}
# fileName <- "csv/amazon_south.csv"
# cl <- parallel::makeCluster(nbrCores)
# doParallel::registerDoParallel(cl)
# #
# tic()
# data <- data.table::fread(paste0(my.path, fileName), sep=";")
# toc()
# stopCluster(cl)
# data
```

## load data

```{r}
tic()
load(file = paste0(my.path, "R_data/amazon_south.Rdata"))
toc()
```
98 sec

```{r}
data[, c("x", "y")] <- floor(data[, c("x", "y")])
data
```

## Create all burnt area data

```{r}
# list of files
amaz.burntArea.list <- list.files(paste0(my.path,"Amazon_new_data/1. Burnt Area/03. Working Data"),
                                  full.names=TRUE,
                                  pattern = ".tif$")
# Import data with "Terra"
burntArea.rast <- rast(amaz.burntArea.list)

#Compute the quartiles
q <- terra::quantile(burntArea.rast)
q1 <- mask(q[[5]], amaz.basin.shp)
names(q1) <-"burntArea"
# plot(q1, col=pal(3))
# writeRaster(q1, paste0(my.path,"Amazon_new_data/1. Burnt Area/q1.tif"), overwrite=TRUE)

# Count number of burn in each cell
ras.nb <- burntArea.rast
ras.nb[ras.nb %in% c(-2, -1)] <- 0

# test3 <- app(x, fun=function(i, ff) ff(i), cores =3, ff=testfun)
ras.sum <- app(ras.nb, fun=sum, cores =30)
amaz.burntArea.sum <- ras.sum %>% mask(mask = amaz.basin.shp)
amaz.burntAreaS.sum <- amaz.burntArea.sum %>% crop(ext(x_min, x_max, y_min, y_max)) 
writeRaster(amaz.burntArea.sum, paste0(path.data,"1. Burnt Area/amazon_burntArea_sum.tif"), overwrite=TRUE)
plot(amaz.burntArea.sum)

# 
library(raster)
ras0 <- q1 -> ras1
ras0[ras0 %in% c(-1, 1)] <- NA
ras1[ras1 <= 0] <- NA
# plot(ras0, col=pal(3)[[2]]); plot(amaz.basin.shp$geometry, add=T)
# plot(ras1, col=pal(3)[[3]]); plot(amaz.basin.shp$geometry, add=T)

# Convert to dataframe
burntArea0 <- as.data.table(ras0, xy=T)
burntArea0[, c("x", "y")] <- floor(burntArea0[, c("x", "y")])
burntArea1 <- as.data.table(ras1, xy=T)
burntArea1[, c("x", "y")] <- floor(burntArea1[, c("x", "y")])
rm(burntArea.rast, q, q1, ras0, ras1);gc()

# burntArea0 <- as.data.table(burntArea0)
# burntArea1 <- as.data.table(burntArea1)
```

# Under sampling the data

## Data sum

```{r}
amaz.burntArea.sum.dt <- as.data.table(amaz.burntArea.sum, xy=T)
amaz.burntArea.sum.dt[, c("x", "y") := lapply(.SD, floor), .SDcols = c("x", "y")] 


amaz.burntAreaS.sum.dt <- as.data.table(amaz.burntAreaS.sum, xy=T)
amaz.burntAreaS.sum.dt[, c("x", "y") := lapply(.SD, floor), .SDcols = c("x", "y")] 
```



## Data1

```{r}
tic()
data1 <- list(data, burntArea1[, -"burntArea"]) %>%
  reduce(inner_join, by=c("x", "y"))
toc()
data1
```

## Data0

```{r}
# burntArea00 <- burntArea0
set.seed(1)
burntArea0.nrow <- nrow(burntArea0)
samp.year <- sample(2001:2020, burntArea0.nrow, replace=T)
samp.month <- sample(1:12, burntArea0.nrow, replace=T)
burntArea0[, `:=` (Year=samp.year, Month=samp.month)]

burntArea0$Month <- fifelse (
  (burntArea0$Year == 2012) & (burntArea0$Month %in% c(7, 9)),
  sample(c(1:6, 8, 10:12), nrow(burntArea0), replace=T),
  burntArea0$Month
)
burntArea0$Month <- as.integer(burntArea0$Month)
burntArea0[(burntArea0$Year == 2012) & (burntArea0$Month %in% c(7, 9)),]
```

```{r}
# burntArea0[((burntArea0$x==-1065061) & (burntArea0$y==2399564)),] 
```

```{r}
# 130 ~ 200 sec
tic()
data0 <- list(data, burntArea0[, -"burntArea"]) %>%
  reduce(inner_join, by=c("x", "y", "Year", "Month"))
toc()
data0
```

## Merge and save final data

```{r}
final.dt <- rbindlist(list(data0, data1), use.names = T, fill = T)
tic()
save(final.dt, file = paste0(my.path, "R_data/amazon_south_und.Rdata"))
toc()
```

```{r}
table(final.dt$burntArea)
```

```{r}
data
```








# Select the data

```{r}
x2_min=-0.88e+06; x2_max=-0.38e+06; y2_min=1.9e+06; y2_max=2.4e+06
data <- data[(data$x %between% c(x2_min, x2_max)) & 
               (data$y %between% c(y2_min, y2_max)), ]
data
```



#=====================

# Load south of Amazon data

```{r}
cl <- parallel::makeCluster(nbrCores)
doParallel::registerDoParallel(cl)
#
tic()
amazon.south <- data.table::fread("~/Documents/csv/amazon_south.csv", sep=";")
toc()
stopCluster(cl)
```

14.159 sec elapsed


# Modification

```{r}
amazon.south <- amazon.south[, Year := as.factor(Year)]
amazon.south <- amazon.south[, Month := as.factor(Month)]
amazon.south <- amazon.south[, burntArea := as.factor(burntArea)]
amazon.south <- amazon.south[, landCover := as.factor(landCover)]

head(amazon.south)
```

# Split data

```{r}
amazS.train.dt <- amazon.south[amazon.south$Year %in% c(2001:2015), ]
amazS.test.dt <- amazon.south[amazon.south$Year %in% c(2016:2020), ]
```


# -------------

```{r, warning=FALSE}
gc()
tic("myForest")
myforest <- randomForest(burntArea~., data=amazS.train.dt, importance=TRUE, na.action = na.omit, do.trace=100)
toc()
```

myForest: 4452.92 sec elapsed


```{r}
myforest
```

```{r}
importance(myforest)
varImpPlot(myforest)
```


## ==============================
## Create Model
## ==============================

```{r}
# Data Partionning 
split = sample.split(amazon.dt$burntArea, SplitRatio = 0.7)
train = subset(amazon.dt, split==TRUE)
test = subset(amazon.dt, split==FALSE)

print(dim(train))
print(dim(test))
table(amazS.train.dt$burntArea) # To check the distribution of area cat and make sure we have good ratio
table(test$burntArea)
```

Our objective here is to use models such as Random Forest and Boosted Tree and perform parameter tuning
To build the best model to predict a fire's severity

# -------------------
# Classficiation Tree
# -------------------

## 1st step: Create a tree maximal Tmax

```{r}
Tmax = rpart(burntArea~., data=amazS.train.dt, minsplit=2, cp=0)
plot(Tmax)
```

## 2nd step: Pruning (delete some part of Tmax) 

```{r}
plotcp(Tmax)
```

```{r}
Tmax.prtcp <- printcp(Tmax)
```

## 3rd step: Selection

```{r}
# Select the minimum error
Tmax.prtcp.df <- as.data.frame(Tmax.prtcp) %>% rownames_to_column(var="id")
Tmax.prtcp.xerr.min <- min(Tmax.prtcp.df$xerror)
Tmax.prtcp.df.min <- Tmax.prtcp.df[Tmax.prtcp.df$xerror==Tmax.prtcp.xerr.min,]

# Compute the threshold of the cross-validation error
Tmax.prtcp.xerr.s <- Tmax.prtcp.df.min$xerror + Tmax.prtcp.df.min$xstd

# Compute the best CP
Tmax.prtcp.df.s <- Tmax.prtcp.df[Tmax.prtcp.df$xerror<Tmax.prtcp.xerr.s,]
Tmax.prtcp.df.s.minNsplit <- min(Tmax.prtcp.df.s$nsplit)
Tmax.prtcp.df.s <- Tmax.prtcp.df.s[Tmax.prtcp.df.s$nsplit==Tmax.prtcp.df.s.minNsplit,]
ind.best.cp <- Tmax.prtcp.df.s$id %>% as.numeric()
Tmax.best.cp <- (Tmax.prtcp.df$CP[ind.best.cp] + Tmax.prtcp.df$CP[ind.best.cp-1])/2

# Tree final
T1 <- prune(Tmax, cp=Tmax.best.cp)

# Plot 
plot(T1)
# text(mytree.final, cex=.5)
```

## Variable importance

```{r}
VI <- T1$variable.importance
VI
```

```{r}
plot(VI)
```

## Predict

```{r}
test_pred <- predict(T1, test, type="class")
err <- 1 - (sum(test$burntArea==test_pred)/nrow(test))
err
```

### Tree final

```{r}
T1 <- prune(Tmax, cp=Tmax.best.cp)
```


# -------------
# Random Forest
# -------------

```{r, warning=FALSE}
gc()
tic()
myforest1 <- randomForest(burntArea~., data=amazon.dt, importance=TRUE, ntree = 500, na.action = na.omit, do.trace=T)
myforest1
toc()
```

```{r}
# plot(myforest1)
plot(myforest1)
myRandomForest <- if (is.null(myforest1$test$err.rate)) {colnames(myforest1$err.rate)} else {colnames(myforest1$test$err.rate)}
legend("top", cex =0.5, legend=myforest1, lty=c(1,2,3), col=c(1,2,3), horiz=T)

```

```{r}
results.RF = data.frame()
myRandomForest <- randomForest(burntArea~., ntree=500, data=train, importance=TRUE, na.action = na.omit)
test_pred <- predict(myRandomForest, test)
sum(test$burntArea==test_pred)/nrow(test)
results.RF <- rbind(results.RF,sum(test$burntArea==test_pred)/nrow(test))

metric_best = 0
params_best <- c(0,0)

split_rf = sample.split(train$burntArea, SplitRatio = 0.85)
train_rf  = subset(train, split_rf==TRUE)
test_rf = subset(train, split_rf==FALSE)

tic("best.rf")
for (ntree in seq(50,500,50)) {
  cat("ntree = ", ntree)
  for (mtry in seq(3,12,1)) {
    cat("mtry = ", mtry)
    myforest=randomForest(burntArea~., ntree=ntree, mtry=mtry, data=train_rf, importance=TRUE, na.action = na.omit)
    test_rf_pred <- predict(myforest, test_rf)
    metric <- sum(test_rf$burntArea==test_rf_pred)/nrow(test_rf)
    # print(c("ntree:",ntree, "mtry:",mtry, "-- metric:",round(metric,digits=4)))
    if (metric>metric_best){
      metric_best <- metric
      params_best <-c(ntree,mtry)
    }
  }
}
toc()

cat("Best model uses:\n")
cat("ntree:", params_best[1], ", mtry:", params_best[2], "-- metric:", round(metric_best, digits=4))
```

best.rf: 12134.56 sec elapsed
Best model uses:
ntree: 50 , mtry: 9 -- metric: 0.997

```{r}
cat("Best model uses:\n")
cat("ntree:", params_best[1], ", mtry:", params_best[2], "-- metric:", round(metric_best, digits=4))
```


```{r}
mybestforest=randomForest(burntArea~., ntree=params_best[1], mtry=params_best[2], data=train, importance=TRUE, na.action = na.omit)
test_pred <- predict(mybestforest, test)
err2 <- 1 - sum(test$burntArea==test_pred)/nrow(test)
err2
```

```{r}
mybestforest
```

```{r}
varImpPlot(mybestforest)
```

## VSURF

```{r}
library(VSURF)
gc()
vatSelect <- VSURF(amazS.train.dt[,-5], amazS.train.dt$burntArea)
```

Thresholding step
Timing stopped at: 82.94 128.5 211.2
 Show Traceback
 Error: cannot allocate vector of size 1545.3 Gb


# ###########
















